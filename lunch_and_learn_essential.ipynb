{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python scikit-learn Machine Learning Workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcomes\n",
    "\n",
    "Example of scikit-learn for supervised machine learning, Xs are measurements\n",
    "\n",
    "- Create training and testing data sets\n",
    "- Create a workflow pipeline\n",
    "- Add a column transformer object\n",
    "- Add a feature selection object\n",
    "- Add a regression object\n",
    "- Fit a model\n",
    "- Set hyperparameters for tuning\n",
    "- Tune the model using grid search cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score,\\\n",
    "        cross_val_predict, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, SCORERS\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "from sklearn import set_config\n",
    "import datasense as ds\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "file_name = 'lunch_and_learn.csv'\n",
    "nrows = 5000\n",
    "graph_name = 'predicted_versus_measured'\n",
    "target = 'Y'\n",
    "features = [\n",
    "    'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7',\n",
    "    'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14'\n",
    "]\n",
    "set_config(display='diagram')\n",
    "title = 'Predicted versus Measured'\n",
    "label_predicted = 'Predicted'\n",
    "label_measured = 'Measured'\n",
    "figure_width_height = (8, 4.5)\n",
    "percent_empty_features = 60.0\n",
    "colour1 = '#0077bb'\n",
    "colour2 = '#33bbee'\n",
    "output_url = 'random_data_test.html'\n",
    "header_title = 'random_data_test'\n",
    "header_id = 'random-data-test'\n",
    "output_url = 'lunch_and_learn_essential.html'\n",
    "header_title = 'lunch_and_learn_essential'\n",
    "header_id = 'lunch-and-learn-essential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(\n",
    "    yvals: pd.Series,\n",
    "    ytext: str,\n",
    "    figwh: Tuple[int, int],\n",
    "    graphname: str\n",
    ") -> None:\n",
    "    '''\n",
    "    Scatter plot of y versus sample order\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figwh)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(yvals, marker='.', linestyle='', color=colour1)\n",
    "    ax.set_ylabel(ytext)\n",
    "    ax.set_ylabel(ytext)\n",
    "    ax.set_title('Time Series')\n",
    "    ds.despine(ax)\n",
    "    plt.savefig(f'{graphname}_time_series_{ytext}.svg')\n",
    "    print(\n",
    "        f'<p><img src=\"{graphname}_time_series_{ytext}.svg\"'\n",
    "        f'alt=\"{graphname}_time_series_{ytext}.svg\"></p>'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_line(\n",
    "    yvals: pd.Series,\n",
    "    xvals: np.ndarray,\n",
    "    ytext: str,\n",
    "    xtext: str,\n",
    "    titletext: str,\n",
    "    figwh: Tuple[int, int],\n",
    "    graphname: str\n",
    ") -> None:\n",
    "    '''\n",
    "    Scatter plot of y versus x\n",
    "    Line of perfect fit\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figwh)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(yvals, xvals, marker='.', linestyle='', color=colour1)\n",
    "    ax.plot([yvals.min(), yvals.max()], [yvals.min(), yvals.max()],\n",
    "            marker=None, linestyle='-', color=colour2)\n",
    "    ax.set_ylabel(ytext)\n",
    "    ax.set_xlabel(xtext)\n",
    "    ax.set_title(titletext)\n",
    "    ds.despine(ax)\n",
    "    plt.savefig(f'{graphname}_scatter.svg')\n",
    "    print(\n",
    "        f'<p><img src=\"{graphname}_scatter.svg\"'\n",
    "        f'alt=\"{graphname}_scatter.svg\"></p>'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_line(\n",
    "    yvals1: pd.Series,\n",
    "    yvals2: np.ndarray,\n",
    "    yvals1text: str,\n",
    "    yvals2text: str,\n",
    "    titletext: str,\n",
    "    figwh: Tuple[int, int],\n",
    "    graphname: str\n",
    ") -> None:\n",
    "    '''\n",
    "    Two line plots of y1, y2\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figwh)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(\n",
    "        yvals1, marker='.', linestyle='-',\n",
    "        color=colour1, label=yvals1text\n",
    "    )\n",
    "    ax.plot(\n",
    "        yvals2, marker='.', linestyle='-',\n",
    "        color=colour2, label=yvals2text\n",
    "    )\n",
    "    ax.set_title(titletext)\n",
    "    ax.legend(frameon=False)\n",
    "    ds.despine(ax)\n",
    "    plt.savefig(f'{graphname}_lines.svg')\n",
    "    print(\n",
    "        f'<p><img src=\"{graphname}_lines.svg\"'\n",
    "        f'alt=\"{graphname}_lines.svg\"></p>'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "\n",
    "Data should be cleaned before fitting a model. A simple example of graphing each feature in sample order and replacing outliers with NaN is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stdout = ds.html_begin(\n",
    "    outputurl=output_url,\n",
    "    headertitle=header_title,\n",
    "    headerid=header_id\n",
    ")\n",
    "ds.page_break()\n",
    "print('<pre style=\"white-space: pre-wrap;\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file into a pandas DataFrame\n",
    "data = ds.read_file(\n",
    "    file_name=file_name,\n",
    "    nrows=nrows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot target versus features\n",
    "for feature in features:\n",
    "    plot_time_series(\n",
    "        data[feature], feature, figure_width_height, graph_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lower and upper values to remove outliers\n",
    "mask_values = [\n",
    "    ('X1', -20, 20),\n",
    "    ('X2', -25, 25),\n",
    "    ('X3', -5, 5),\n",
    "    ('X4', -10, 10),\n",
    "    ('X5', -3, 3),\n",
    "    ('X6', -5, 5),\n",
    "    ('X7', -13, 13),\n",
    "    ('X8', -9, 15),\n",
    "    ('X9', -17, 15),\n",
    "    ('X10', -16, 15),\n",
    "    ('X11', -16, 17),\n",
    "    ('X12', -16, 17),\n",
    "    ('X13', -20, 23)\n",
    "]\n",
    "# Replace outliers with NaN\n",
    "for column, lowvalue, highvalue in mask_values:\n",
    "    data[column]= data[column].mask(\n",
    "        (data[column] <= lowvalue) |\n",
    "        (data[column] >= highvalue)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows if target is NaN\n",
    "data = data.dropna(subset=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features if > percent_empty_features\n",
    "features = ds.feature_percent_empty(\n",
    "    df=data,\n",
    "    columns=features,\n",
    "    limit=percent_empty_features\n",
    ")\n",
    "ds.page_break()\n",
    "print('Features')\n",
    "print(features)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing data sets\n",
    "X_all = data[features]\n",
    "y_all = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning workflow\n",
    "\n",
    "A typical workflow involves several, sequential steps:\n",
    "\n",
    "- Column transformation such as imputing missing values\n",
    "- Feature selection\n",
    "- Modeling\n",
    "\n",
    "These steps are embedded in a workflow method called a pipeline, which is simply a series of sequential steps. The output of each step is passed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow 1\n",
    "\n",
    "- Impute using the mean\n",
    "- Select features using SelectFromModel(DecisionTreeRegressor)\n",
    "- Fit with LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print('Workflow 1')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the imputer object with\n",
    "# the default hyperparameter settings\n",
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformer object\n",
    "ct = make_column_transformer(\n",
    "    (imp, features),\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a feature selection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects to use for feature selection with\n",
    "# the default hyperparameter settings\n",
    "linreg_selection = LinearRegression()\n",
    "dtr_selection = DecisionTreeRegressor()\n",
    "lasso_selection = Lasso()\n",
    "lassocv_selection = LassoCV()\n",
    "rfr_selection = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature selection object\n",
    "selection = SelectFromModel(estimator=dtr_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object to use for regression with\n",
    "# the default hyperparameter settings\n",
    "linreg = LinearRegression()\n",
    "dtr = DecisionTreeRegressor()\n",
    "lasso = Lasso()\n",
    "lassocv = LassoCV()\n",
    "rfr = RandomForestRegressor()\n",
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a workflow object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow object\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('transformer', ct),\n",
    "        ('selector', selection),\n",
    "        ('regressor', linreg)\n",
    "    ]\n",
    ")\n",
    "print(pipe)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine the linear regression model\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the selected features \n",
    "print('Selected features')\n",
    "print(X_all.columns[selection.get_support()])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the regression intercept\n",
    "print('Regression intercept')\n",
    "print(pipe.named_steps.regressor.intercept_.round(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the regression coefficients of the features\n",
    "print('Regression coefficients')\n",
    "print(pipe.named_steps.regressor.coef_.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation estimates how accurately a predictive model will perform in practice. The model is fitted using the training data set and tested using the testing data set. cross_val_score performs the columns transformations, specified in column transformer, after each of the data splits in order to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate the updated pipeline\n",
    "print('Cross-validation score')\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5, n_jobs=-1).mean().round(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this the best score? Should we explore other methods for feature selection? Should we use other than the default setting for the hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters are values you set, such as 'mean' in SimpleImputer(). Parameters are values learned in the fit step. We tune the hyperparameters for all of the objects in the pipeline. You define the values to try for each hyperparameter. GridSearchCV performs cross-validation for every possible combination of these values for the entire pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters for optimization\n",
    "# Create a dictionary\n",
    "# The dictionary key is the step name, followed by two underscores,\n",
    "# followed by the hyperparameter name\n",
    "# The dictionary value is the list of values to try per hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 x 3 x 3 x 2 = 72\n",
    "hyperparams = [\n",
    "    {\n",
    "        'transformer': [imp],\n",
    "        'transformer__strategy': [\n",
    "            'mean', 'median', 'most_frequent', 'constant'\n",
    "        ],\n",
    "        'selector': [SelectFromModel(estimator=dtr_selection)],\n",
    "        'selector__threshold': [None, 'mean', 'median'],\n",
    "        'selector__estimator__criterion': [\n",
    "            'mse', 'friedman_mse', 'mae'\n",
    "        ],\n",
    "#        'selector__estimator__splitter': ['best', 'random'],\n",
    "#        'selector__estimator__max_features': [\n",
    "#            None, 'auto', 'sqrt', 'log2'\n",
    "#        ],\n",
    "#        'selector__estimator__max_leaf_nodes': [None, 2, 4, 6],\n",
    "        'regressor': [linreg],\n",
    "        'regressor__normalize': [False, True]\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hyperparams.append(\\n    {\\n        'transformer': [imp],\\n        'transformer__strategy': [\\n            'mean', 'median', 'most_frequent', 'constant'\\n        ],\\n        'selector': [SelectFromModel(estimator=linreg_selection)],\\n        'selector__threshold': [None, 'mean', 'median'],\\n        'selector__estimator__normalize': [False, True],\\n        'regressor': [linreg],\\n        'regressor__normalize': [False, True]\\n    },\\n)\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''hyperparams.append(\n",
    "    {\n",
    "        'transformer': [imp],\n",
    "        'transformer__strategy': [\n",
    "            'mean', 'median', 'most_frequent', 'constant'\n",
    "        ],\n",
    "        'selector': [SelectFromModel(estimator=linreg_selection)],\n",
    "        'selector__threshold': [None, 'mean', 'median'],\n",
    "        'selector__estimator__normalize': [False, True],\n",
    "        'regressor': [linreg],\n",
    "        'regressor__normalize': [False, True]\n",
    "    },\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhyperparams.append(\\n   {\\n        'transformer': [imp],\\n        'transformer__strategy': [\\n            'mean', 'median', 'most_frequent', 'constant'\\n        ],\\n        'selector': [SelectFromModel(estimator=lasso_selection)],\\n        'selector__threshold': [None, 'mean', 'median'],\\n        'selector__estimator__normalize': [False, True],\\n        'regressor': [linreg],\\n        'regressor__normalize': [False, True]\\n    },\\n)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hyperparams.append(\n",
    "   {\n",
    "        'transformer': [imp],\n",
    "        'transformer__strategy': [\n",
    "            'mean', 'median', 'most_frequent', 'constant'\n",
    "        ],\n",
    "        'selector': [SelectFromModel(estimator=lasso_selection)],\n",
    "        'selector__threshold': [None, 'mean', 'median'],\n",
    "        'selector__estimator__normalize': [False, True],\n",
    "        'regressor': [linreg],\n",
    "        'regressor__normalize': [False, True]\n",
    "    },\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 x 3 x 2 x 2 = 48\n",
    "hyperparams.append(\n",
    "   {\n",
    "        'transformer': [imp],\n",
    "        'transformer__strategy': [\n",
    "            'mean', 'median', 'most_frequent', 'constant'\n",
    "        ],\n",
    "        'selector': [SelectFromModel(estimator=lassocv_selection)],\n",
    "        'selector__threshold': [None, 'mean', 'median'],\n",
    "        'selector__estimator__normalize': [False, True],\n",
    "        'regressor': [linreg],\n",
    "        'regressor__normalize': [False, True]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhyperparams.append(\\n\\n    {\\n\\n        'transformer': [imp],\\n\\n        'transformer__strategy': [\\n\\n            'mean', 'median', 'most_frequent', 'constant'\\n\\n        ],\\n\\n        'selector': [SelectFromModel(estimator=rfr_selection)],\\n\\n        'selector__threshold': [None, 'mean', 'median'],\\n\\n        'selector__estimator__criterion': ['mse', 'mae'],\\n\\n        'regressor': [linreg],\\n\\n        'regressor__normalize': [False, True]\\n\\n    },\\n\\n)\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hyperparams.append(\n",
    "\n",
    "    {\n",
    "\n",
    "        'transformer': [imp],\n",
    "\n",
    "        'transformer__strategy': [\n",
    "\n",
    "            'mean', 'median', 'most_frequent', 'constant'\n",
    "\n",
    "        ],\n",
    "\n",
    "        'selector': [SelectFromModel(estimator=rfr_selection)],\n",
    "\n",
    "        'selector__threshold': [None, 'mean', 'median'],\n",
    "\n",
    "        'selector__estimator__criterion': ['mse', 'mae'],\n",
    "\n",
    "        'regressor': [linreg],\n",
    "\n",
    "        'regressor__normalize': [False, True]\n",
    "\n",
    "    },\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform a grid search\n",
    "grid = GridSearchCV(pipe, hyperparams, n_jobs=-1, cv=5)\n",
    "grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Present the results\n",
    "pd.DataFrame(grid.cv_results_).sort_values('rank_test_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the best score\n",
    "print('Hyperparameter optimization')\n",
    "print('Best score')\n",
    "print(grid.best_score_.round(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the best hyperparameters\n",
    "print('Best hyperparameters')\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.479"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "round((end_time - start_time).total_seconds(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow 2\n",
    "\n",
    "- Impute using the mean\n",
    "- Select features using SelectFromModel(LassoCV())\n",
    "- Fit with LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "ds.page_break()\n",
    "print('Workflow 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the imputer object\n",
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformer object\n",
    "ct = make_column_transformer(\n",
    "     (imp, features),\n",
    "     remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a feature selection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object to use for feature selection\n",
    "lassocv_selection = LassoCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature selection object\n",
    "selection = SelectFromModel(\n",
    "    estimator=lassocv_selection,\n",
    "    threshold='median'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects to use for regression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a workflow object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow object\n",
    "pipe = make_pipeline(ct, selection, linreg)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the linear regression model\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the selected features \n",
    "# selected = pd.DataFrame(X.columns[selection.get_support()])\n",
    "selected_features = X_all.columns[selection.get_support()].to_list()\n",
    "print('Selected features')\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_coefficients = pipe.named_steps.linearregression.coef_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_importances = np.abs(\n",
    "    pipe.named_steps.selectfrommodel.estimator_.coef_[selection.get_support()]\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(\n",
    "    list(zip(\n",
    "        selected_features, selected_importances, selected_coefficients)),\n",
    "    columns=['Features', 'Importance', 'Coefficients']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the regression intercept\n",
    "print('Regression intercept')\n",
    "print(pipe.named_steps.linearregression.intercept_.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate the updated pipeline\n",
    "# sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cross-validation score')\n",
    "print(cross_val_score(\n",
    "    pipe, X_train, y_train, cv=5, n_jobs=-1,\n",
    "    scoring='r2'\n",
    ").mean().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predicted values\n",
    "predicted = cross_val_predict(pipe, X_all, y_all, cv=5, n_jobs=-1)\n",
    "mse = mean_squared_error(y_all, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error')\n",
    "print(mse.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error')\n",
    "print(round(math.sqrt(mse), 3))\n",
    "ds.page_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted versus measured\n",
    "plot_scatter_line(\n",
    "    y_all, predicted, label_predicted, label_measured, title,\n",
    "    figure_width_height, graph_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted versus measured\n",
    "plot_line_line(y_all, predicted, label_measured, label_predicted, title,\n",
    "               figure_width_height, graph_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('</pre>')\n",
    "ds.html_end(\n",
    "    originalstdout=original_stdout,\n",
    "    outputurl=output_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.506"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "round((end_time - start_time).total_seconds(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "## numpy\n",
    "\n",
    "- [API](https://numpy.org/devdocs/reference/index.html)\n",
    "\n",
    "## pandas\n",
    "\n",
    "- [API](https://pandas.pydata.org/docs/reference/index.html)\n",
    "\n",
    "- [isna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html)\n",
    "\n",
    "- [mask](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html#pandas.DataFrame.mask)\n",
    "\n",
    "- [options.display.max_rows, options.display.max_columns](https://pandas.pydata.org/docs/reference/api/pandas.set_option.html#pandas.set_option)\n",
    "\n",
    "- [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv)\n",
    "\n",
    "- [shape](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html)\n",
    "\n",
    "## python\n",
    "\n",
    "- [library reference](https://docs.python.org/3/library/index.html)\n",
    "\n",
    "- [datetime](https://docs.python.org/3/library/datetime.html)\n",
    "\n",
    "## scikit-learn\n",
    "\n",
    "- [API](https://scikit-learn.org/stable/modules/classes.html#)\n",
    "\n",
    "- [compose module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose)\n",
    "\n",
    "- [compose.make_column_transformer function](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html#sklearn.compose.make_column_transformer)\n",
    "\n",
    "- [ensemble module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "\n",
    "- [ensemble.RandomForestRegressor class](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "\n",
    "- [feature_selection module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)\n",
    "\n",
    "- [feature_selection.SelectFromModel class](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel)\n",
    "\n",
    "- [feature_selection.SelectFromModel.get_support() method](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel.get_support)\n",
    "\n",
    "- [feature_selection.SelectKBest class](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)\n",
    "\n",
    "- [feature_selection.f_regression scoring function](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "\n",
    "- [impute module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute)\n",
    "\n",
    "- [impute SimpleImputer class](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)\n",
    "\n",
    "- [linear_model module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "\n",
    "- [linear_model.Lasso class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n",
    "\n",
    "- [linear_model.LassoCV class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)\n",
    "\n",
    "- [linear_model.LinearRegression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "\n",
    "- [linear models User Guide](https://scikit-learn.org/stable/modules/linear_model.html#linear-model)\n",
    "\n",
    "- [linear regression example](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "\n",
    "- [model_selection module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "\n",
    "- [model_selection cross_val_score function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
    "\n",
    "- [model_selection GridSearchCV class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "\n",
    "- [model_selection train_test_split function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)\n",
    "\n",
    "- [pipeline module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline)\n",
    "\n",
    "- [pipeline.make_pipeline function](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline)\n",
    "\n",
    "- [tree module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree)\n",
    "\n",
    "- [tree.DecisionTreeRegressor class](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)\n",
    "\n",
    "## XGBoost\n",
    "\n",
    "- [API](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
    "\n",
    "- [XGBRegressor class](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "\n",
    "## statsmodels\n",
    "\n",
    "- [API](https://www.statsmodels.org/stable/api.html)\n",
    "\n",
    "## Machine learning\n",
    "\n",
    "- [cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n",
    "\n",
    "- [feature selection](https://en.wikipedia.org/wiki/Feature_selection)\n",
    "\n",
    "- [hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)\n",
    "\n",
    "- [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics))\n",
    "\n",
    "- [linear regression](https://en.wikipedia.org/wiki/Linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary\n",
    "\n",
    "**ColumnTransformer** It is a Class in scikit-learn that applies transformers to columns in a data set.\n",
    "\n",
    "**Cross validation** It is a model validation technique for estimating how accurately a predictive model will perform in practice. In a prediction problem, a model is usually given a dataset of known data on which training is performed (training data set) and a data set of unknown data (or first-seen data) against which the model is tested (testing data set). Cross validation tests the model's ability to predict new data that was not used in estimating it in order to identify problems such as overfitting or selection bias, and to give insight on how the model will generalize to an independent (unknown) data set. One round of cross validation involves partitioning a sample of data into complementary subsets, performing the analyis on one subset (training set) and validating the analysis on the other subset (testing set). To reduce variability in the results, multiple rounds of cross validation are performed using different partitions and the validation results are combined (averaged) over the rounds to give an estimate of the model's predictive performance.\n",
    "\n",
    "**Data leakage** It is inadvertently including knowledge from the testing data when training a model. The model will be less reliable. This may lead to incorrect decisions when tuning hyperparameters. This may lead to overestimating how well the model will perform on new data.\n",
    "\n",
    "**Decision tree** It is a non-parametric supervised machine learning method used for classification and regression. It uses feature importance to determine potential features that could be in the model.\n",
    "\n",
    "**Feature** It is an independent variable that is controlled in order to cause an outcome in the dependent variable.\n",
    "\n",
    "**Feature selection** It is the process of selecting a set of features for a model. The data set probably contains features that are redundant or irrelevant, and can be removed with little effect on a model.\n",
    "\n",
    "**Hyperparameter** It is a value you set during the model fitting process.\n",
    "\n",
    "**Linear regression** It is a linear approach to modeling the relationship between a target and one or more features, using linear predictor functions where unknown model parameters are estimated from the data.\n",
    "\n",
    "**Machine Learning** Machine learning algortihms build a mathematical model on a training data subset in order to make predictions on a test data subset. Various measures are used to compare the actual and predicted data in the test data subset to estimate the performance of the model.\n",
    "\n",
    "**Mask** It is a pandas function that replaces a value with another value, a NaN by default.\n",
    "\n",
    "**Parameter** It is a value learned during the model fitting process.\n",
    "\n",
    "**Pipeline** A pipeline is a series of sequential steps. The output of each step is passed to the next step. It is a scikit-learn Class that applies one or more column transformations and a final estimator. The final estimator only needs to implement fit.The purpose is to assemble several steps that can be cross-validated together while setting different hyperparameters.\n",
    "\n",
    "**Target** It is a dependent variable that represents the outcome resulting from altering features (independent variables).\n",
    "\n",
    "**Testing data set** It is the data set upon which we use the model and put the values of the features to predict the target in order to compare the actual target values with the predicted values in order to evaluate the performance of the model.\n",
    "\n",
    "**Training data set** It contains known values of the target. The model learns from these data, that is, we fit a model to estimate the relationship between the target and the features.\n",
    "\n",
    "**Transformer** It is a scikit-learn object that transforms a column. For example, it can replace NaN with the average of all values in a column.\n",
    "\n",
    "**Workflow** It is a repeatable pattern of activity, a sequence of operations. In scikit-learn, workflow is achieved through the Pipeline class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
